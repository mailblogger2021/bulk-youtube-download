{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import Tool\n",
    "from langchain.graph import GraphExecutor\n",
    "from langchain.visualization import visualize_graph\n",
    "\n",
    "# Define the LLM (Large Language Model) you will use\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.5)\n",
    "\n",
    "# Step 1: Define a custom tool to fetch data\n",
    "def fetch_data(query: str) -> str:\n",
    "    # This is a placeholder for fetching data, e.g., from a database or API.\n",
    "    return f\"Fetched data for the query: {query}\"\n",
    "\n",
    "fetch_tool = Tool(\n",
    "    name=\"FetchTool\",\n",
    "    func=fetch_data,\n",
    "    description=\"Tool to fetch data based on the query\"\n",
    ")\n",
    "\n",
    "# Step 2: Define the first chain to process the query and fetch data\n",
    "prompt_1 = PromptTemplate(input_variables=[\"query\"], template=\"What do you know about {query}?\")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "\n",
    "# Step 3: Define the second chain to summarize the fetched data\n",
    "prompt_2 = PromptTemplate(input_variables=[\"data\"], template=\"Summarize this data: {data}\")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
    "\n",
    "# Step 4: Add memory to the chain for keeping track of previous context (optional)\n",
    "memory = ConversationBufferMemory()\n",
    "chain_1_with_memory = LLMChain(llm=llm, prompt=prompt_1, memory=memory)\n",
    "chain_2_with_memory = LLMChain(llm=llm, prompt=prompt_2, memory=memory)\n",
    "\n",
    "# Step 5: Create a graph of the agent architecture (flow of chains)\n",
    "graph = {\n",
    "    \"input\": [\"fetch_tool\"],\n",
    "    \"fetch_tool\": [\"chain_1_with_memory\"],\n",
    "    \"chain_1_with_memory\": [\"chain_2_with_memory\"],\n",
    "    \"chain_2_with_memory\": [\"output\"]\n",
    "}\n",
    "\n",
    "# Step 6: Execute the graph using GraphExecutor\n",
    "executor = GraphExecutor(graph=graph, tools={\"fetch_tool\": fetch_tool, \"chain_1_with_memory\": chain_1_with_memory, \"chain_2_with_memory\": chain_2_with_memory})\n",
    "\n",
    "# Step 7: Define input data for testing\n",
    "input_data = {\"query\": \"LangChain\"}\n",
    "\n",
    "# Run the agent architecture\n",
    "output = executor.run(input_data)\n",
    "\n",
    "# Step 8: Print the output result\n",
    "print(f\"Final Output: {output}\")\n",
    "\n",
    "# Step 9: Visualize the agent's graph architecture\n",
    "visualize_graph(graph)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
